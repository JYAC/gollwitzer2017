---
title: "Replication of Gollwitzer et al., 2017 by Mechanical Turk (2017,  Nature Human Behavior)"
author: "Julie Cachia (jcachia@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

### Justification for choice of experiment:

This study looks at how aversion to non-social pattern deviancy predicts aversion towards stigmatized individuals. This paper is related to my interests because part of the cross-cultural work I will be doing in my lab will investigate how we react to people who don't match our affective preferences (ideal affect). 

### Description of paper: 

Across 8 studies, this paper (Gollwitzer, Marshall, Wang & Bargh, 2017) showed that aversion to non-social deviancy (in patterns and shapes) predicted aversion to social deviancy (stigmatized individuals, norm breakers, negative and positive deviants, and minority groups).

I aim to replicate Study 1 for this project. Specifically, I will conduct a linear regression to test whether aversion to pattern deviancy significantly predicts aversion to social deviancy. 

### Description of the stimuli and procedures that will be required to conduct this experiment:

Participants will be recruited via Amazon's Mechanical Turk. 

The measures:

-Political orientation (3 items)

-Need for closure (15 items)

-Neuroticism (2 items)

-Pattern deviancy (15 items)

-Social deviancy (15 items)

-Attention check (2 items)

-Demographics: income (1 item); education (1 item)

### Anticipated challenges:

-Ensuring I have the intended sample size even after excluding participants who failed the attention check

### Links:

Project Repository: https://github.com/JYAC/gollwitzer2017

Original Paper: https://github.com/JYAC/gollwitzer2017/tree/master/original_paper

Qualtrics Survey: https://stanforduniversity.qualtrics.com/jfe/form/SV_1SlT9mNwFnIOpEh

### References:

Gollwitzer, A., Marshall, J., Wang, Y., & Bargh, J. A. (2017). Relating pattern deviancy aversion to stigma and prejudice. *Nature Human Behaviour*, *1*(12), 920.


## Methods

### Power Analysis

The original effect size was 0.38 (standardized beta coefficient). Power analysis revealed that in order to detect this effect size, we need the following sample sizes for each level of power:

to achieve 80% power, we need N = 49;

to achieve 90% power, we need N = 65; 

to achieve 95% power, we need N = 79. 

The full survey takes about 5 minutes (4 minutes when I tried) to complete. Therefore, in order to be consistent with Califronia minimum wage ($11/hour), each participant should get paid \$0.92 per survey. In order to stay within the course budget of \$50, we will choose 80% power.

The original paper reports a 9% exclusion rate (for failing the attention check), so assuming the same exclusion rate, we will need 54 participants, and the full $50:

[N - (0.09N)] = 49 

N = 53.84 (54 participants required)

**54 participants x $0.92 = \$49.68**

### Planned Sample

Planned sample size will be 54 participants (accounting for 9% exclusion rate), based on the power analysis conducted above. 

### Materials

Quoted from the original article: 


"*Need for closure.* We included a validated short version of the need-for-closure scale26. The scale consisted of 15 items (for example, ‘I don’t like situations that are uncertain’).

*Neuroticism.* We included a validated two-item neuroticism scale: ‘I see myself as someone who… is relaxed, handles stress well’ (reverse-coded) and ‘I see myself as someone who… gets nervous easily’27,54.

*Political orientation.* Participants answered the following questions on a Likert scale ranging from 1 (extremely liberal) to 9 (extremely conservative): ‘In terms of economic issues, how liberal or conservative are you?’, ‘In terms of social and cultural issues, how liberal or conservative are you?’ and ‘Where on the following scale of political orientation would you place yourself?’

*Pattern deviancy.* We assessed participants’ aversion in response to five images depicting non-social pattern deviancy (see Supplementary Methods for images). These images were taken from popular Buzzfeed.com articles presenting images depicting non-social pattern deviancy. For example, one of these articles was named: ‘31 things that will make any neat freak’s eye twitch’ (https://www.buzzfeed.com/erinchack/things-that-will-make-any-neat-freaks-eye-twitch?utm_term=
.gjMkaOGJR#.xbwoO1jQY). Underneath each image, a prompt read ‘The above image makes me…’ followed by three statements assessing participants’ discomfort, anxiousness, and annoyance in response to the image (‘feel uncomfortable’, ‘feel anxious’, and ‘feel annoyed’). Participants answered on a Likert scale from 1 (not at all agree) to 7 (strongly agree). The images were presented in random order.

*Social deviancy.* Social deviancy aversion was measured identically to pattern deviancy aversion except that the images depicted deviant individuals (see Supplementary Methods for images). These images were validated as depicting socially deviant individuals in Supplementary Study 2.

*Attention check items.* We included a direct (‘I was focused while filling out this survey’) and indirect attention check item (‘People vary in the amount they pay attention to these kinds of surveys… if you have read this question carefully, please write the word yes in the blank box below labeled other.’; see Supplementary Note for details). The same two attention check items were used as exclusion criteria in studies 2–6."

The [exact scales described above](https://stanforduniversity.qualtrics.com/jfe/form/SV_1SlT9mNwFnIOpEh) were used in this replication. 

### Procedure	

Quoted from the original article: 

"Before beginning the study, participants gave informed consent (the same is true of all reported studies). Participants then completed the need for closure, neuroticism, and political orientation measures in random order. Thereafter, they completed the pattern and social deviancy measures in random order. Lastly, participants completed the attention check items and demographics (the same is true of studies 2–6). No consistent demographic effects were found across the reported studies (see Supplementary Note for details)."

The exact procedure outlined above was followed. 


### Analysis Plan

First, participants who failed the attention check were excluded, defined as follows in the supplementary materials:

"Our first attention check item assessed whether participants were focused (“I was focused while filling out this survey”). Likert-scale: 1 (strongly disagree) to 7 (strongly agree). **Only participants who replied with 6 or 7 to this item were included in the analyses.** The second item indirectly assessed participants’ attention: “People vary in the amount they pay attention to these kinds of surveys. Some take them seriously and read each question, whereas others go very quickly and barely read the questions at all. If you have read this question carefully, please write the word yes in the blank box below labeled other. There is no need for you to respond to the scale below.” Participants were then presented with a Likert scale (1 to 7) and a text-box labeled “other.” **Only participants who wrote “yes,” “YES,” or “Yes” into the text-box were included in the analyses.**"

Next, compute pattern deviancy aversion scores for each participant by averaging the three items used to assess 1) discomfort, 2) anxiousness, and 3) annoyance in response to the 5 pattern deviance images.

Similarly, compute social deviancy aversion scores for each participant by averaging the three items used to assess 1) discomfort, 2) anxiousness, and 3) annoyance in response to the 5 social deviance images.

Compute Need for Closure score for each participant by calculating the mean score across all 15 items.

Compute Neuroticism score for each participant by: 1) reverse coding first item, and 2) calculating the mean of the two items.

**Key analysis of interest**: Linear regression testing whether pattern deviancy aversion (IV) predicts social deviancy aversion (DV). 

Additional analyses: Repeat the above linear regression, but this time controlling for Need for Closure, Neuroticism, and Political Orientation to see whether the association remains. 

### Differences from Original Study

Since the original study was also coducted on MTurk, I don't expect big differences in our sample. However, it is possible that the MTurk population is slightly different now (in 2018) than when the original study was conducted (2017).

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


##Results


### Data preparation

Data preparation following the analysis plan.

	
```{r}

###Data Preparation

setwd("/Users/juliecachia/Desktop/RProjects/Replication Data") #Set working directory

####Load Relevant Libraries and Functions
library(tidyverse)
library(ggplot2)

####Import data

RawData <- read_csv("test.csv")

#### Data exclusion / filtering

RawData <- RawData[3:nrow(RawData),] #Take out 2 first heading rows

#Rename attention check columns
colnames(RawData)[colnames(RawData)=="Q2"] <- "AttentionCheck1" 
colnames(RawData)[colnames(RawData)=="Q3_8_TEXT"] <- "AttentionCheck2" 

#Using filter function in tidyverse, exclude participants who failed attention checks: 1) scoring below 6 on first item, and/or 2) not entering "Yes", "yes", or "Yes" into the text field of the second item
PassedACheck1 <- RawData$AttentionCheck1 > 5 
PassedACheck2 <- grepl("yes", RawData$AttentionCheck2, ignore.case=TRUE) 

#Filter dataset to obtain only those rows that passed both attention checks
ExcludedData <- filter(RawData, PassedACheck1 & PassedACheck2) 

#### Prepare data for analysis - create columns

#Include participant id column so that later I can group_by(id)
ExcludedData <- ExcludedData %>% 
  mutate(id = row_number())

#Reverse code Item 1 ("Q40_1") of Neuroticism Scale, which is in column 18 of dataframe:
ExcludedData[,18:70]<- lapply(ExcludedData[,18:70], as.numeric) #Change class to numeric
ExcludedData[,18] = 6 - ExcludedData[,18] #Reverse code by subtracting every value from 6

###Column names for items of relevant variables:
#Pattern Deviancy Items: Q11_1, Q11_2, Q11_3, Q12_1, Q12_2, Q12_3, Q13_1, Q13_2, Q13_3, Q14_1, Q14_2, Q14_3, Q15_1, Q15_2, Q15_3
#Social Deviancy Items: Q17_1, Q17_2, Q17_3, Q18_1, Q18_2, Q18_3, Q19_1, Q19_2, Q19_3, Q20_1, Q20_2, Q20_3, Q21_1, Q21_2, Q21_3
#Need for Closure Items: Q23, Q24, Q25, Q26, Q27, Q28, Q29, Q30, Q31, Q34, Q35, Q36, Q37, Q38, Q39
#Neuroticism Items: Q40_1, Q40_2
#Political Orientation Item: Q4

#Make data tidy
TidyData <- ExcludedData %>%
  gather(Q11_1, Q11_2, Q11_3, Q12_1, Q12_2, Q12_3, Q13_1, Q13_2, Q13_3, Q14_1, Q14_2, Q14_3, Q15_1, Q15_2, Q15_3, key = "PatternDevItems", value = "PatternDevRating") %>%
  gather(Q17_1, Q17_2, Q17_3, Q18_1, Q18_2, Q18_3, Q19_1, Q19_2, Q19_3, Q20_1, Q20_2, Q20_3, Q21_1, Q21_2, Q21_3, key = "SocialDevItems", value = "SocialDevRating")%>%
  gather(Q23, Q24, Q25, Q26, Q27, Q28, Q29, Q30, Q31, Q34, Q35, Q36, Q37, Q38, Q39, key = "NeedforClosureItems", value = "NeedforClosureRating") %>%
  gather(Q40_1, Q40_2, key = "NeuroticismItems", value = "NeuroticismRating")

#Create final dataframe specifically for the key analysis
OnlyKeyColumns <- TidyData %>%
  group_by(id) %>%
  summarise(PatternDevAversion = mean(PatternDevRating), #Mean of 15 items
            SocialDevAversion = mean(SocialDevRating), #Mean of 15 items
            NeedforClosure= mean(NeedforClosureRating),#Mean of 15 items
            Neuroticism = mean(NeuroticismRating), #Mean of 2 items
            PoliticalOrientation = mean(Q4)) #Same value

OnlyKeyColumns #Output final dataframe
```

### Confirmatory analysis
 
```{r}
#Conduct linear regression to test whether Pattern Deviancy Aversion predicts Social Deviancy Aversion
KeyAnalysis <- lm(SocialDevAversion ~ PatternDevAversion, data=OnlyKeyColumns) 
summary(KeyAnalysis)
```

*Side-by-side graph with original graph is ideal here* #No graph of this in original paper
```{r}
ggplot(OnlyKeyColumns, aes(x=PatternDevAversion, y=SocialDevAversion))+
  geom_point()+
  geom_smooth(method=lm)+
  ggtitle("Dependence of Social Deviancy Aversion on Pattern Deviancy Aversion")+
  xlab("Pattern Deviancy Aversion")+
  ylab("Social Deviancy Aversion")
```


### Exploratory analyses

```{r}
#Controlling for Need for Closure, Neuroticism, and Political Orientation:
AdditionalAnalysis <- lm(SocialDevAversion ~ PatternDevAversion + NeedforClosure + Neuroticism + PoliticalOrientation, data=OnlyKeyColumns)  #include 3 covariates
summary(KeyAnalysis)
```

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
